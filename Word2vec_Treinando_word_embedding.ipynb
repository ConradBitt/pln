{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec_Treinando_word_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP32hH8tyeQGiDWUM0xBOkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConradBitt/processamento_linguagem_natural/blob/master/Word2vec_Treinando_word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj4JCcaXABY7"
      },
      "source": [
        "# Introdução \n",
        "\n",
        "Este notebook tem como objetivo criar representações textuais através de **word2vec**, um classificador de títulos de reportagens de jornal. Posteriormente, após a representação, treino e teste do modelo, será disponibilizado através de uma aplicação web visando simular um ambiente de produção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0SgmcDmbM-U"
      },
      "source": [
        "## Montando Drive\n",
        "\n",
        "O motivo de usar o colaboratory é porque processamento de linguagem envolve muita memoria RAM e portanto rodar localmente pode se tonar um tanto custoso.Além disso, através do calab é permitido montar uma imagem do drive onde podemos armazenar os dados. Por esses dois motivos optei pelo google colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SOvvisDnK3a",
        "outputId": "0c9b2133-778d-498c-9f1d-93e01f962ee0"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXV3bkNN_4QT",
        "outputId": "cd193822-bd60-4b7e-f3a2-f3e5514f6b9e"
      },
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import spacy\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "sns.set_context('talk')\n",
        "\n",
        "# Executar apenas uma vez e depois reiniciar o ambiente de execução.\n",
        "#!python -m spacy download pt_core_news_sm\n",
        "\n",
        "print('~ Versões dos Módulos ~')\n",
        "print(f'Pandas: {pd.__version__}')\n",
        "print(f'Seaborn: {sns.__version__}')\n",
        "print(f'Numpy: {np.__version__}')\n",
        "print(f'Matplotlib: {mpl.__version__}')\n",
        "print(f'Spacy: {spacy.__version__}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~ Versões dos Módulos ~\n",
            "Pandas: 1.1.5\n",
            "Seaborn: 0.11.1\n",
            "Numpy: 1.19.5\n",
            "Matplotlib: 3.2.2\n",
            "Spacy: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNYVUjemnXNl"
      },
      "source": [
        "# Lendo os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZaArhCRncYy"
      },
      "source": [
        "treino = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/word2vec/dados/treino.csv')\n",
        "teste = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/word2vec/dados/teste.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4EqTpwtnfhw"
      },
      "source": [
        "## Informações datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "sFTpZiRqnkJr",
        "outputId": "15e8a021-a79a-4858-e41a-eb1614fc27e9"
      },
      "source": [
        "display(treino.info())\n",
        "display(teste.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 90000 entries, 0 to 89999\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   title        90000 non-null  object\n",
            " 1   text         90000 non-null  object\n",
            " 2   date         90000 non-null  object\n",
            " 3   category     90000 non-null  object\n",
            " 4   subcategory  17175 non-null  object\n",
            " 5   link         90000 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 4.1+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20513 entries, 0 to 20512\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   title        20513 non-null  object\n",
            " 1   text         20513 non-null  object\n",
            " 2   date         20513 non-null  object\n",
            " 3   category     20513 non-null  object\n",
            " 4   subcategory  6794 non-null   object\n",
            " 5   link         20513 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 961.7+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S80bUTTAnnhY"
      },
      "source": [
        "Temos: \n",
        "* 90000 observações nos dados de treino, totalizando 4.1MB.\n",
        "* 20513 observações nos dados de teste, totalizando 961KB\n",
        "\n",
        "todos os dados são do tipo object, porvavelmente strings dividos em 6 variaveis, `titulo`, `text`, `date`, `category`, `subcategory`, `link`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2BVwskinkXa"
      },
      "source": [
        "## Exibindo alguns dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "2L6CHKddp_i5",
        "outputId": "dff76bc7-6cc0-41c9-face-c236737d47ef"
      },
      "source": [
        "treino.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
              "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
              "      <td>2017-04-28</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
              "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
              "      <td>2017-04-23</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
              "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
              "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
              "      <td>2015-07-24</td>\n",
              "      <td>cotidiano</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
              "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
              "      <td>2017-08-17</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...                                               link\n",
              "0  Após polêmica, Marine Le Pen diz que abomina n...  ...  http://www1.folha.uol.com.br/mundo/2017/04/187...\n",
              "1  Macron e Le Pen vão ao 2º turno na França, em ...  ...  http://www1.folha.uol.com.br/mundo/2017/04/187...\n",
              "2  Apesar de larga vitória nas legislativas, Macr...  ...  http://www1.folha.uol.com.br/mundo/2017/06/189...\n",
              "3  Governo antecipa balanço, e Alckmin anuncia qu...  ...  http://www1.folha.uol.com.br/cotidiano/2015/07...\n",
              "4  Após queda em maio, a atividade econômica sobe...  ...  http://www1.folha.uol.com.br/mercado/2017/08/1...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmPvwfIGqCUj"
      },
      "source": [
        "Usaremos a variável ``title`` para tentar estimar a variável ``category``. Entretanto, vamos analisar como é apresentada uma observação:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "95etqPL2qW09",
        "outputId": "d1695723-8165-41e5-8b0a-6b84366150e8"
      },
      "source": [
        "treino.title.iloc[-10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Pagamento de propina pode chegar a R$ 50 mil por carga'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKkY_yOFqb1l"
      },
      "source": [
        "perceba que temos palavras, números e caracteres especiais \"\\$\", então é necessário um pré processamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeMB9SLcqAcH"
      },
      "source": [
        "# Pre processamento \n",
        "\n",
        "Geralmente se utiliza o NLTK para fazer a filtragem de caracteres e tokenização. Neste notebook vou utilizar o [spaCy](https://spacy.io/) um módulo escrito em  Python e Cython para processamento de linguagem natural.\n",
        "\n",
        "A documentação esta disponível em: \n",
        "\n",
        "> https://spacy.io/api\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl30vGajsjGO"
      },
      "source": [
        "## Instalando SpaCy\n",
        "\n",
        "Para instalar o SpaCy segue-se as instruções no site:\n",
        "\n",
        "> https://spacy.io/usage\n",
        "\n",
        "Entretanto no colab ele já vem instalado por padrão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDcJgwrRs1xl"
      },
      "source": [
        "O que precisamo fazer é baixar a lingua cujo os nossos dados foram escritos, no mesmo site tem as linhas que devem ser executadas para instalar o idioma portguês:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dood_GD8tM-O"
      },
      "source": [
        "# Executar apenas uma vez e depois reiniciar o ambiente de execução.\n",
        "#!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wBKBLMKtmpy"
      },
      "source": [
        "Para testar se o idioma desejado foi instalado executamos o comando. **Depois de baixar os dados é necessário reiniciar o ambiente de execução.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4h48HIHtqUG"
      },
      "source": [
        "nlp = spacy.load('pt_core_news_sm')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIOnijovwoTq"
      },
      "source": [
        "### Exemplo de uso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqL2dl5sxL-V",
        "outputId": "d75b8c35-386e-4e30-bb57-b2a1dbafe9b3"
      },
      "source": [
        "meu_texto = treino.title.iloc[22]\n",
        "print(meu_texto)\n",
        "\n",
        "doc = nlp(meu_texto)\n",
        "print(type(doc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jon Snow volta aos holofotes em vídeo da 6ª temporada de 'Game of Thrones'\n",
            "<class 'spacy.tokens.doc.Doc'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TErZMGqgweEW"
      },
      "source": [
        "Note que o nlp tem objetos do tipo ``Doc``, para saber o que esse objeto contém, podemos analisar a documentação:\n",
        "\n",
        "> https://spacy.io/usage/spacy-101#pipelines\n",
        "\n",
        "A descrição do Doc é: \n",
        "\n",
        "> A Doc is a sequence of Token objects. Access sentences and named entities, export annotations to numpy arrays, losslessly serialize to compressed binary strings. The Doc object holds an array of TokenC structs. The Python-level Token and Span objects are views of this array, i.e. they don’t own the data themselves. Fonte: [https://spacy.io/api/doc](https://spacy.io/api/doc)\n",
        "\n",
        "Basicamente quando instanciamos um objeto ``Doc`` o ``nlp`` faz uma série de processamentos, como tokenização, targge, parser, entre outros, até criar o objeto.\n",
        "\n",
        "<img src='https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg' width=80%>\n",
        "\n",
        "> Fonte: https://spacy.io/usage/spacy-101#pipelines\n",
        "\n",
        "Os objetos ``Doc`` tem atributos muito uteis, podemos consultar em\n",
        "\n",
        "> https://spacy.io/api/doc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Htzsm5xxqe",
        "outputId": "2997b5f5-a9b8-415c-9fde-b744e91d01e0"
      },
      "source": [
        "print('Meu Doc: ', doc)\n",
        "print('Entidades de doc: ', doc.ents)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Meu Doc:  Jon Snow volta aos holofotes em vídeo da 6ª temporada de 'Game of Thrones'\n",
            "Entidades de doc:  (Jon Snow, Game of Thrones)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbM4Y4qezj6K"
      },
      "source": [
        "O objeto consegue identificar varias classificações dos elementos que compõem a frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2irt4eL0viF",
        "outputId": "3b9596cc-ca3a-4830-f816-195e235ffb2e"
      },
      "source": [
        "print(doc.text, '\\n')\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jon Snow volta aos holofotes em vídeo da 6ª temporada de 'Game of Thrones' \n",
            "\n",
            "Jon PROPN nsubj\n",
            "Snow PROPN flat:name\n",
            "volta VERB ROOT\n",
            "a ADP case\n",
            "os DET det\n",
            "holofotes PROPN obl\n",
            "em ADP case\n",
            "vídeo NOUN obl\n",
            "da ADP case\n",
            "6ª ADJ amod\n",
            "temporada NOUN nmod\n",
            "de ADP case\n",
            "' PUNCT punct\n",
            "Game PROPN nmod\n",
            "of PROPN flat:name\n",
            "Thrones PROPN flat:name\n",
            "' PUNCT punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpAInrqhQVyZ"
      },
      "source": [
        "é possível utilizar varios métodos dos tokens, por exemplo a representação da palavra em um espaço vetorial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYoH3FrdQZ6V",
        "outputId": "2ccf6f3c-c20f-42c3-f06e-5c1351322cbd"
      },
      "source": [
        "print(doc[1], '=', doc[1].vector)\n",
        "\n",
        "print('\\nNorma do vetor')\n",
        "print(doc[1], '=', doc[1].vector_norm)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snow = [  2.7633104    7.462899     0.63145417   0.7640705    1.4044249\n",
            "   1.0847819   -5.712425    -2.5970128    3.591257     6.957478\n",
            "  11.282299     1.5133985   -5.667033    -1.6723096   -0.7537353\n",
            "  -1.4369892   -2.0909038    0.29047918   4.8055325   -4.069366\n",
            "  -3.749087    -1.4293463   -2.5723786    0.60486764  -4.8334146\n",
            "  -7.603295     0.38302672  -3.394683    -1.864464    -7.2505016\n",
            "  -2.334701    -5.8551       7.2367682    3.8455513    1.262495\n",
            " -10.394055     3.4092844   -4.875017     0.09814078   5.481478\n",
            "   1.432259    -1.1912625   -7.294257    -2.0385437   -1.3923185\n",
            "  -0.9888474   -4.113654     2.6139627   -1.9440972    3.370472\n",
            "  -3.3382788   -8.765093     0.6188494    2.0189853   -7.73819\n",
            "   9.392529     0.10228646   2.750429     1.814964    -2.7373686\n",
            "  -1.5277661   -2.0538282    9.940031    -1.2688947    6.332727\n",
            "  -8.138163     2.3974452   -0.10324526  -2.9152355   -0.81570804\n",
            "   2.6807451   -5.3069367    4.2606955   -7.808796    -0.45525482\n",
            "   2.3871043    1.4407995    5.228157     1.3777741    3.0054917\n",
            "   3.0935416    2.7068386    5.017227     4.783826     0.9116301\n",
            "   7.0248013   -7.414099    -0.49483967   7.6248903    2.488573\n",
            "   2.4533658   -7.1282387    1.0999506    3.819768     1.076453\n",
            "   3.3711514 ]\n",
            "\n",
            "Norma do vetor\n",
            "Snow = 43.630646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLKcwRQ_SZvq"
      },
      "source": [
        "Podemos fazer análise de sentimento em relação ao ``token``:\n",
        "\n",
        "> ``sentiment``\tA scalar value indicating the positivity or negativity of the token. ``float``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F1Rm5_CSvjf",
        "outputId": "ec6c34c1-2b48-43b0-de57-985033f71c1b"
      },
      "source": [
        "for token in doc:\n",
        "  print(token.sentiment)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By24571N0x6t"
      },
      "source": [
        "existem varios outros atributos e métodos disponíveis para tokens, disponíveis na documentação:\n",
        "\n",
        "> https://spacy.io/api/token\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93B7G8J8RXiw"
      },
      "source": [
        "## Algumas modificações e Generator Expression\n",
        "\n",
        "Precisamos dos títulos tratados adequadamente para ser utilizados em modelos. Para isso é necessario uma função que faça essa modificação.\n",
        "\n",
        "Antes disso vou deixar todos os dados em minusculo pois não faz diferença entre \"comissão\" e \"Comissão\".\n",
        "\n",
        "> **Em vez de usar list comprehensions utilizarei um gerador criado através do generator expression. Basicamente cria um gerador para ser utilizado em tempo de execução. Para saber mais: [List Comprehension vs Generator Expressions in Python](https://code-maven.com/list-comprehension-vs-generator-expression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUG_Qt0I35ie",
        "outputId": "1e625f31-8e3d-49db-f76f-58f9e3f3ba04"
      },
      "source": [
        "\n",
        "texto_para_tratamento = (titulo.lower() for titulo in treino.title)\n",
        "print(f'O gerador: {texto_para_tratamento}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O gerador: <generator object <genexpr> at 0x7fd08db985d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyOYZLcZ5LeT"
      },
      "source": [
        "em vez de receber um gerador a função para tratar os textos vai receber um ``Doc`` para conseguirmos realizar as seguintas rotinas:\n",
        "\n",
        "* Remover stopwords \"O, A, do, da, na, se, aqueles\", palavras irrelevantes para entender o contexto.\n",
        "\n",
        "* Ter apenas caracteres alphabeticos \n",
        "\n",
        "* Título com no mínomo três palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aTjRBHU3GHB"
      },
      "source": [
        "def trata_textos(doc):\n",
        "  \"\"\"\n",
        "  Esta função trata os textos recebidos,\n",
        "  remove stopwords, retorna alphanumericos\n",
        "  maior que três palavras.\n",
        "  \"\"\"\n",
        "  tokens_validos = []\n",
        "  for token in doc: \n",
        "    # variável de validação\n",
        "    # garante que o token não é stopword e é alphanumerico\n",
        "    e_valido = not token.is_stop and token.is_alpha\n",
        "    if e_valido:\n",
        "      tokens_validos.append(token.text)\n",
        "      \n",
        "  if len(tokens_validos) > 2:\n",
        "    return \" \".join(tokens_validos)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtbmGkef7-4M"
      },
      "source": [
        "Testando a função:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "vQJjHNGs3QEY",
        "outputId": "7c65b81a-a1a4-41e7-9093-799ffddd4571"
      },
      "source": [
        "print(doc)\n",
        "trata_textos(doc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jon Snow volta aos holofotes em vídeo da 6ª temporada de 'Game of Thrones'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jon Snow volta a holofotes vídeo temporada Game of Thrones'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1MiqvqJJf8W"
      },
      "source": [
        "Um ponto importante é que o ``doc`` que criamos recebeu uma ``string``, mas precisamos passar uma estrtura de dados para ``nlp``, para saber como fazer isso precisamos entender como funciona a classe ``nlp``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDyBwbd6J50S",
        "outputId": "85a7ed67-5d50-486d-84fe-8f2d58ecd6ef"
      },
      "source": [
        "type(nlp)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.pt.Portuguese"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saLfk-_QLqBK"
      },
      "source": [
        "Olhando a [documentação do ``spacy.lang``](https://spacy.io/api/language#init) um dos parâmetros utilizados pelo ``__init__()`` é o ``batch_size`` e para passar uma estrutura de dados com textos para o ``nlp`` utiliza-se um \"pipeline\" uma linha de processos, o seguinte exemplo ilustra como fazer isso: \n",
        "\n",
        "```python\n",
        "texts = [\"One document.\", \"...\", \"Lots of documents\"]\n",
        "for doc in nlp.pipe(texts, batch_size=50):\n",
        "    assert doc.has_annotation(\"DEP\")\n",
        "```\n",
        "\n",
        "Além do ``batch_size`` passado ao  ``nlp.pipe``, podemos dizer quantos batchs serão processados por cada núcleo através do parâmetro ``n_processor`` descrito na documentação do pipe:\n",
        "\n",
        "> https://spacy.io/api/language#pipe\n",
        "\n",
        "> ``n_process`` \tNumber of processors to use. Defaults to 1.\n",
        "int\n",
        "\n",
        "para ver quantos núcleos de processamento a máquina virtual do colab basta usar o comando\n",
        "> ``lscpu | grep -E '^Thread|^Core|^Socket|^CPU\\('``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcfTp0RBLq2g",
        "outputId": "c4263ff6-11a4-4db7-8857-5ac2afaa8f01"
      },
      "source": [
        "!lscpu | grep -E '^Thread|^Core|^Socket|^CPU\\('"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU(s):              2\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vQSvC5PymK"
      },
      "source": [
        "caso não saiba quantos núcleos de processamento tem, é possível passar ``n_process=-1`` ai o spacy irá utilizar todos os disponíveis.\n",
        "\n",
        "<font color=red ><b>Lembrando que esse processo pode demorar!</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRnjtPfJ7gVt",
        "outputId": "5b46807e-0ec0-47bd-a90c-6a2ed4edbf5d"
      },
      "source": [
        "texto_tratado = [trata_textos(doc) for doc in nlp.pipe(texto_para_tratamento,\n",
        "                                                      batch_size=1000,\n",
        "                                                      n_process = -1)]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 54min 5s, sys: 1min 22s, total: 1h 55min 28s\n",
            "Wall time: 2h 1min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIOvjCDMy6u1"
      },
      "source": [
        "\n",
        "### Salvando objeto\n",
        "vou salvar est objeto para evitar que demore todo este tempo toda vez que for necessario executar este notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p1Pd4ghzBID"
      },
      "source": [
        "import pickle\n",
        "\n",
        "file_texto_tratado = open(b'texto_tratado.obj','wb')\n",
        "pickle.dump(texto_tratado, file_texto_tratado)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YjpuicFz6Gv"
      },
      "source": [
        "### Lendo objeto salvo\n",
        "\n",
        "para ler o objeto salvo através do pickle, usamos a seguinte sintaxe, depois de baixar o arquivo:\n",
        "\n",
        "https://github.com/ConradBitt/processamento_linguagem_natural/blob/master/texto_tratado.obj\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtgqKH470nlV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "texto_tratado_objeto = open(b'texto_tratado.obj', 'rb')\n",
        "texto_tratado_lido_pickle = pickle.load(texto_tratado_objeto)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT5grfrB1D7I",
        "outputId": "57ed0f8a-0fe9-42b9-d6ab-32016e2f71ba"
      },
      "source": [
        "texto_tratado_lido_pickle[:15]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ataques multiplicam israel e cisjordânia morrem gaza',\n",
              " 'dutra trânsito lento chegada a paulo',\n",
              " 'alta chicago bulls felício destaque brasil nba',\n",
              " 'sábato influenciou críticos hoje questionado',\n",
              " 'diretor israelense humor superar a dor perda shivá',\n",
              " 'continuação universidade columbia analisa erros rolling stone reportagem',\n",
              " 'el niño trará impactos enormes alertam cientistas',\n",
              " 'folha lança aplicativo realidade virtual filme percorre sp',\n",
              " 'platini suspensão fraude e promete recorrer uefa francês',\n",
              " 'premiê israel pressionado a cancelar visita donald trump',\n",
              " None,\n",
              " 'grêmio chega a acordo barrios e espera liberação palmeiras',\n",
              " 'perspectivas abrem o mercosul',\n",
              " 'governo campanha prevenção a hiv aplicativo gay',\n",
              " 'brilho eterno mente lembranças terá série tv site']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZhYckXv23ez"
      },
      "source": [
        "> **Referência**: https://www.greelane.com/pt/ci%C3%AAncia-tecnologia-matem%C3%A1tica/ci%C3%AAncia-da-computa%C3%A7%C3%A3o/using-pickle-to-save-objects-2813661"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EScUVC2B2AX2"
      },
      "source": [
        "## Tratando entradas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kqcl7PlMQHpo",
        "outputId": "8aa0e060-10df-4b81-a690-77aae6ea2871"
      },
      "source": [
        "titulos_tratados = pd.DataFrame(\n",
        "    {'titulo':texto_tratado}\n",
        ")\n",
        "\n",
        "titulos_tratados.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ataques multiplicam israel e cisjordânia morre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dutra trânsito lento chegada a paulo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alta chicago bulls felício destaque brasil nba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sábato influenciou críticos hoje questionado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diretor israelense humor superar a dor perda s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              titulo\n",
              "0  ataques multiplicam israel e cisjordânia morre...\n",
              "1               dutra trânsito lento chegada a paulo\n",
              "2     alta chicago bulls felício destaque brasil nba\n",
              "3       sábato influenciou críticos hoje questionado\n",
              "4  diretor israelense humor superar a dor perda s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9YzMCCW1YKj",
        "outputId": "1971066f-5e45-42c3-cd33-a06ece689abb"
      },
      "source": [
        "titulos_tratados.info()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 86000 entries, 0 to 85999\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   titulo  82479 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 672.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7-i74OTS7u_"
      },
      "source": [
        "# Treinando modelo Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpAuMI233oJS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}