{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sixth-studio",
   "metadata": {},
   "source": [
    "# Introdução \n",
    "\n",
    "O objetivo deste notebook é aprender as chamadas word embedding que são basicamente transformações de textos em vetores, forma que será utilizada para a transformação é conhecida como *one-hot-encoding* que transforma em matrizes esparças de ordem $n$\n",
    "\n",
    "Além disso, será abordado alguns assuntos sobre o Word2vec que é uma forma de representar uma palavra através de um vetor denso também de tamanho fixo, a vantagem de dessa representação é que muitos modelos conseguem entender o contexto da palavra, por exemplo as palavras *Brasil, China, Peugeot, Ferrari, Bulgaria*, podem ser classificadas em países e carros.\n",
    "\n",
    "A diferença do one-hot-encoding é que as palavras são vetores independentes e não tem conexão entre elas, já em word2vec as palavras são expressas em vetores que pertencem a um espaço vetorial capaz de clusterizar grupos de palavras de um mesmo contexto.\n",
    "\n",
    "O Word2vec é extremamente poderozo, pois funciona de duas formas. A primeira é dado um contexto, por exemplo: \n",
    "\n",
    "> **Morar no país ____** \n",
    "\n",
    "ele consegue estimar soluções para  possível frase. Matematicamente a modelagem é:\n",
    "\n",
    "$$\\vec{v} = (\\text{morar, no, país})$$\n",
    "\n",
    "$$T(\\vec{v}) = \\text{europeu}.$$\n",
    "\n",
    "Existe outra forma de utilizar o Word2Vec, que é, através da palavra tentar estimar o contexto, por exemplo:\n",
    "\n",
    "> **____ __ ____ europeu**\n",
    "\n",
    "basicamente será encontrar a transformação $T$ inversa, essa técnica é chamada de skipgram ou *proximo grama*.\n",
    "\n",
    "O contexto dos dados são notícias de um blog genérico:\n",
    "\n",
    "* [Dados de treino](https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/treino.csv)\n",
    "\n",
    "* [Dados de teste](https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/teste.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesser-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_treino = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/treino.csv'\n",
    "uri_teste = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/teste.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-insight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
